{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrg3ao24YsPd",
        "outputId": "23be599b-5776-4024-8d01-31871857b8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-code-management'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 19 (delta 3), reused 18 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (19/19), 5.80 KiB | 5.80 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mubtasimahasan/deep-learning-code-management.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHL008gQY53z",
        "outputId": "342c2e7c-1e41-4390-dffe-62faf30f84da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"deep-learning-code-management\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-Z51o2_tA3j",
        "outputId": "f5144db4-5efa-49dd-9722-3ad513cd87ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning-code-management\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ddMswF6fZHTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5dbe923-f8e9-4e32-a95c-021083e28bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning-code-management\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V2pe1sOibiNK",
        "outputId": "80b7b414-abb7-46eb-d139-0bbdbbfae244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (8.1.7)\n",
            "Collecting numpy==1.26.4 (from -r requirements.txt (line 3))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.3.0 (from -r requirements.txt (line 4))\n",
            "  Downloading Pillow-9.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch_lightning==2.0.9.post0 (from -r requirements.txt (line 5))\n",
            "  Downloading pytorch_lightning-2.0.9.post0-py3-none-any.whl (727 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.7/727.7 kB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (6.0.1)\n",
            "Requirement already satisfied: torch==2.1+cu121 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.1.0+cu121)\n",
            "Collecting torchmetrics==1.2.0 (from -r requirements.txt (line 8))\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision==0.16+cu121 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.16.0+cu121)\n",
            "Collecting wandb==0.16.3 (from -r requirements.txt (line 10))\n",
            "  Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->-r requirements.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->-r requirements.txt (line 1)) (0.19.3)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->-r requirements.txt (line 1)) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->-r requirements.txt (line 1)) (4.9.0.80)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5)) (4.66.2)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5)) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5)) (4.9.0)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5))\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1+cu121->-r requirements.txt (line 7)) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1+cu121->-r requirements.txt (line 7)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1+cu121->-r requirements.txt (line 7)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1+cu121->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1+cu121->-r requirements.txt (line 7)) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16+cu121->-r requirements.txt (line 9)) (2.31.0)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb==0.16.3->-r requirements.txt (line 10))\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.3->-r requirements.txt (line 10)) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb==0.16.3->-r requirements.txt (line 10))\n",
            "  Downloading sentry_sdk-1.40.5-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb==0.16.3->-r requirements.txt (line 10))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb==0.16.3->-r requirements.txt (line 10))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.3->-r requirements.txt (line 10)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.3->-r requirements.txt (line 10)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.3->-r requirements.txt (line 10)) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb==0.16.3->-r requirements.txt (line 10)) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5)) (3.9.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb==0.16.3->-r requirements.txt (line 10))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.1->-r requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16+cu121->-r requirements.txt (line 9)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16+cu121->-r requirements.txt (line 9)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16+cu121->-r requirements.txt (line 9)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16+cu121->-r requirements.txt (line 9)) (2024.2.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->-r requirements.txt (line 1)) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->-r requirements.txt (line 1)) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->-r requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1+cu121->-r requirements.txt (line 7)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1+cu121->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==2.0.9.post0->-r requirements.txt (line 5)) (4.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.16.3->-r requirements.txt (line 10))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1->-r requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1->-r requirements.txt (line 1)) (3.3.0)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, Pillow, numpy, lightning-utilities, docker-pycreds, gitdb, torchmetrics, GitPython, wandb, pytorch_lightning\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "Successfully installed GitPython-3.1.42 Pillow-9.3.0 docker-pycreds-0.4.0 gitdb-4.0.11 lightning-utilities-0.10.1 numpy-1.26.4 pytorch_lightning-2.0.9.post0 sentry-sdk-1.40.5 setproctitle-1.3.3 smmap-5.0.1 torchmetrics-1.2.0 wandb-0.16.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRtkxtPUZeub",
        "outputId": "1f450811-cf21-41c2-aa43-022a50c8e4c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 42\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100% 528M/528M [00:04<00:00, 133MB/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmubtasimahasan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m__logs__/wandb/run-20240224_154533-regular\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33mregular\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mubtasimahasan/dl-code-management-experiment\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mubtasimahasan/dl-code-management-experiment/runs/regular\u001b[0m\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to __data__/cifar-10-python.tar.gz\n",
            "100% 170498071/170498071 [00:05<00:00, 28942399.91it/s]\n",
            "Extracting __data__/cifar-10-python.tar.gz to __data__\n",
            "Files already downloaded and verified\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Adjusting learning rate of group 0 to 1.0000e-01.\n",
            "\n",
            "  | Name   | Type             | Params\n",
            "--------------------------------------------\n",
            "0 | model  | VGG              | 134 M \n",
            "1 | metric | MetricCollection | 0     \n",
            "--------------------------------------------\n",
            "134 M     Trainable params\n",
            "0         Non-trainable params\n",
            "134 M     Total params\n",
            "537.206   Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:   0% 0/5 [00:00<?, ?it/s] Adjusting learning rate of group 0 to 9.0000e-02.\n",
            "Epoch 0: 100% 5/5 [00:04<00:00,  1.11it/s, v_num=ular]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  4.22it/s]\u001b[A\n",
            "Epoch 0: 100% 5/5 [00:08<00:00,  1.62s/it, v_num=ular, val_loss=1.2e+22]Epoch 0, global step 5: 'F1' reached 0.07494 (best 0.07494), saving model to '/content/deep-learning-code-management/__logs__/dl-code-management-experiment/regular/last-best.ckpt' as top 1\n",
            "Epoch 1:   0% 0/5 [00:00<?, ?it/s, v_num=ular, val_loss=1.2e+22]Adjusting learning rate of group 0 to 8.1000e-02.\n",
            "Epoch 1: 100% 5/5 [00:03<00:00,  1.38it/s, v_num=ular, val_loss=1.2e+22]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  4.15it/s]\u001b[A\n",
            "Epoch 1: 100% 5/5 [00:07<00:00,  1.59s/it, v_num=ular, val_loss=3.47e+21]Epoch 1, global step 10: 'F1' was not in top 1\n",
            "Epoch 2:   0% 0/5 [00:00<?, ?it/s, v_num=ular, val_loss=3.47e+21]Adjusting learning rate of group 0 to 7.2900e-02.\n",
            "Epoch 2: 100% 5/5 [00:03<00:00,  1.32it/s, v_num=ular, val_loss=3.47e+21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  4.00it/s]\u001b[A\n",
            "Epoch 2: 100% 5/5 [00:07<00:00,  1.53s/it, v_num=ular, val_loss=3.19e+19]Epoch 2, global step 15: 'F1' was not in top 1\n",
            "Epoch 3:   0% 0/5 [00:00<?, ?it/s, v_num=ular, val_loss=3.19e+19]Adjusting learning rate of group 0 to 6.5610e-02.\n",
            "Epoch 3: 100% 5/5 [00:04<00:00,  1.08it/s, v_num=ular, val_loss=3.19e+19]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.90it/s]\u001b[A\n",
            "Epoch 3: 100% 5/5 [00:08<00:00,  1.73s/it, v_num=ular, val_loss=2.62e+19]Epoch 3, global step 20: 'F1' reached 0.07679 (best 0.07679), saving model to '/content/deep-learning-code-management/__logs__/dl-code-management-experiment/regular/last-best.ckpt' as top 1\n",
            "Epoch 4:   0% 0/5 [00:00<?, ?it/s, v_num=ular, val_loss=2.62e+19]Adjusting learning rate of group 0 to 5.9049e-02.\n",
            "Epoch 4: 100% 5/5 [00:03<00:00,  1.35it/s, v_num=ular, val_loss=2.62e+19]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  4.55it/s]\u001b[A\n",
            "Epoch 4: 100% 5/5 [00:07<00:00,  1.58s/it, v_num=ular, val_loss=14.90]Epoch 4, global step 25: 'F1' was not in top 1\n",
            "Epoch 5:   0% 0/5 [00:00<?, ?it/s, v_num=ular, val_loss=14.90]Adjusting learning rate of group 0 to 5.3144e-02.\n",
            "Epoch 5: 100% 5/5 [00:03<00:00,  1.32it/s, v_num=ular, val_loss=14.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  4.03it/s]\u001b[A\n",
            "Epoch 5: 100% 5/5 [00:07<00:00,  1.47s/it, v_num=ular, val_loss=3.12e+19]Epoch 5, global step 30: 'F1' was not in top 1\n",
            "Epoch 6:   0% 0/5 [00:00<?, ?it/s, v_num=ular, val_loss=3.12e+19]Adjusting learning rate of group 0 to 4.7830e-02.\n",
            "Epoch 6: 100% 5/5 [00:03<00:00,  1.30it/s, v_num=ular, val_loss=3.12e+19]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.75it/s]\u001b[A\n",
            "Epoch 6: 100% 5/5 [00:07<00:00,  1.56s/it, v_num=ular, val_loss=7.18e+18]Epoch 6, global step 35: 'F1' reached 0.07726 (best 0.07726), saving model to '/content/deep-learning-code-management/__logs__/dl-code-management-experiment/regular/last-best.ckpt' as top 1\n",
            "Epoch 7:   0% 0/5 [00:00<?, ?it/s, v_num=ular, val_loss=7.18e+18]Adjusting learning rate of group 0 to 4.3047e-02.\n",
            "Epoch 7: 100% 5/5 [00:04<00:00,  1.11it/s, v_num=ular, val_loss=7.18e+18]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  4.51it/s]\u001b[A\n",
            "Epoch 7: 100% 5/5 [00:08<00:00,  1.67s/it, v_num=ular, val_loss=8.010]Epoch 7, global step 40: 'F1' reached 0.08087 (best 0.08087), saving model to '/content/deep-learning-code-management/__logs__/dl-code-management-experiment/regular/last-best.ckpt' as top 1\n",
            "Epoch 8:   0% 0/5 [00:00<?, ?it/s, v_num=ular, val_loss=8.010]Adjusting learning rate of group 0 to 3.8742e-02.\n",
            "Epoch 8: 100% 5/5 [00:04<00:00,  1.04it/s, v_num=ular, val_loss=8.010]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.81it/s]\u001b[A\n",
            "Epoch 8: 100% 5/5 [00:08<00:00,  1.63s/it, v_num=ular, val_loss=4.840]Epoch 8, global step 45: 'F1' reached 0.08421 (best 0.08421), saving model to '/content/deep-learning-code-management/__logs__/dl-code-management-experiment/regular/last-best.ckpt' as top 1\n",
            "Epoch 9:   0% 0/5 [00:00<?, ?it/s, v_num=ular, val_loss=4.840]Adjusting learning rate of group 0 to 3.4868e-02.\n",
            "Epoch 9: 100% 5/5 [00:03<00:00,  1.33it/s, v_num=ular, val_loss=4.840]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.66it/s]\u001b[A\n",
            "Epoch 9: 100% 5/5 [00:08<00:00,  1.68s/it, v_num=ular, val_loss=2.13e+17]Epoch 9, global step 50: 'F1' reached 0.08906 (best 0.08906), saving model to '/content/deep-learning-code-management/__logs__/dl-code-management-experiment/regular/last-best.ckpt' as top 1\n",
            "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
            "Epoch 9: 100% 5/5 [00:32<00:00,  6.43s/it, v_num=ular, val_loss=2.13e+17]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ensure read and write access to run files dir: __logs__/wandb/run-20240224_154533-regular/files, control this via the WANDB_DIR env var. See https://docs.wandb.ai/guides/track/environment-variables\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  F1 ▂▁▂▃▂▁▃▅▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         F1_airplane ▂▁▇▇▆██▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       F1_automobile █▇▆▅▄▃▃▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             F1_bird ▃▂▂▁▁▁▂▂▂█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              F1_cat █▅▄▃▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             F1_deer ▃▂▁▇██▇▇▆▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              F1_dog █▅▄▂▂▁▇▆▆▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             F1_frog ▁█▇▇▆▆▆▅▅▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            F1_horse █▆▄▃▂▁▁▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             F1_ship ▄▃▂▁▁▂█▇▇▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            F1_truck ▇▅▄▃▂▂▁▁██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch ▁▂▃▃▄▅▆▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step ▁▂▃▃▄▅▆▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss █▃▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  F1 0.08906\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         F1_airplane 0.1277\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       F1_automobile 0.11225\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             F1_bird 0.09355\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              F1_cat 0.00371\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             F1_deer 0.15006\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              F1_dog 0.0577\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             F1_frog 0.09192\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            F1_horse 0.10983\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             F1_ship 0.04577\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            F1_truck 0.09808\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step 49\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss 2.1257913143761306e+17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mregular\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mubtasimahasan/dl-code-management-experiment/runs/regular\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m__logs__/wandb/run-20240224_154533-regular/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python cli.py train --config ./configs/VGG16_CIFAR10.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9T8CdOreDUA",
        "outputId": "63f803f7-18b3-4d8f-f421-a0c87225d1d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 42\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Restoring states from the checkpoint path at __logs__/dl-code-management-experiment/regular/last-best.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from the checkpoint at __logs__/dl-code-management-experiment/regular/last-best.ckpt\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Testing DataLoader 0: 100% 10/10 [00:03<00:00,  3.02it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m           F1            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.030130529776215553   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       F1_airplane       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      F1_automobile      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         F1_bird         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2026471346616745    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         F1_cat          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         F1_deer         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         F1_dog          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09865818172693253   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         F1_frog         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        F1_horse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         F1_ship         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        F1_truck         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 2.4086731505742643e+17  \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n"
          ]
        }
      ],
      "source": [
        "!python cli.py test --config ./configs/VGG16_CIFAR10.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBf3DJxIhXgw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}